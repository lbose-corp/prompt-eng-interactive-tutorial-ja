{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章: 基本的なプロンプト構造\n",
    "\n",
    "- [レッスン](#レッスン)\n",
    "- [演習](#演習)\n",
    "- [サンプルプレイグラウンド](#サンプルプレイグラウンド)\n",
    "\n",
    "## セットアップ\n",
    "\n",
    "以下のセットアップセルを実行して、APIキーを読み込み、`get_completion`ヘルパー関数を確立します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Import the hints module from the utils package\n",
    "import os\n",
    "import sys\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import hints\n",
    "\n",
    "# Retrieve the MODEL_NAME variable from the IPython store\n",
    "%store -r MODEL_NAME\n",
    "%store -r AWS_REGION\n",
    "\n",
    "client = boto3.client('bedrock-runtime',region_name=AWS_REGION)\n",
    "\n",
    "def get_completion(prompt,system=''):\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": '',\n",
    "            \"max_tokens\": 2000,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": 0.0,\n",
    "            \"top_p\": 1,\n",
    "            \"system\": system\n",
    "        }\n",
    "    )\n",
    "    response = client.invoke_model(body=body, modelId=MODEL_NAME)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    return response_body.get('content')[0].get('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## レッスン\n",
    "\n",
    "AnthropicはレガシーのClaude APIと現在のMessages APIの2つのAPIを提供しています。このチュートリアルでは、Messages APIのみを使用します。\n",
    "\n",
    "最小限のMessages APIを使用したClaudeへの呼び出しには、以下のパラメータが必要です：\n",
    "- `model`: 呼び出すモデルの[APIモデル名](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns)\n",
    "\n",
    "- `max_tokens`: 生成を停止する前の最大トークン数。Claudeはこの最大値に達する前に停止する場合があります。このパラメータは生成する絶対的な最大トークン数のみを指定します。さらに、これはハードストップであり、Claudeが単語や文の途中で生成を停止する可能性があります。\n",
    "\n",
    "- `messages`: 入力メッセージの配列。私たちのモデルは、交互に`user`と`assistant`の会話ターンで動作するように訓練されています。新しい`Message`を作成する際、messagesパラメータで以前の会話ターンを指定し、モデルは会話の次の`Message`を生成します。\n",
    "  - 各入力メッセージは`role`と`content`を持つオブジェクトでなければなりません。単一の`user`ロールメッセージを指定するか、複数の`user`と`assistant`メッセージを含めることができます（その場合、交互でなければなりません）。最初のメッセージは常にユーザーの`role`を使用する必要があります。\n",
    "\n",
    "また、以下のようなオプションのパラメータもあります：\n",
    "- `system`: システムプロンプト - これについては後で詳しく説明します。\n",
    "  \n",
    "- `temperature`: Claudeの応答の変動性の度合い。これらのレッスンと演習では、`temperature`を0に設定しています。\n",
    "\n",
    "すべてのAPIパラメータの完全なリストについては、[APIドキュメント](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-claude.html)をご覧ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例\n",
    "\n",
    "Claudeが正しくフォーマットされたプロンプトにどのように応答するか見てみましょう。以下の各セルについて、セルを実行（`shift+enter`）すると、Claudeの応答がブロックの下に表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"こんにちわ、Claude。お元気ですか?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"あなたは海の色をなんと呼んでいますか?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"セリーヌ・ディオンは何年生まれですか?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、正しいMessages APIのフォーマットを含まないプロンプトを見てみましょう。これらの不正なフォーマットのプロンプトに対して、Messages APIはエラーを返します。\n",
    "\n",
    "まず、`messages`配列に`role`と`content`フィールドがないMessages API呼び出しの例を示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⚠️ **警告:** プロンプトのmessagesパラメータの不正なフォーマットにより、以下のセルはエラーを返します。これは予期された動作です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": '',\n",
    "        \"max_tokens\": 2000,\n",
    "        \"messages\": [{\"こんにちは、Claude。お元気ですか?\"}],\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 1,\n",
    "        \"system\": ''\n",
    "    }\n",
    ")\n",
    "\n",
    "response = client.invoke_model(body=body, modelId=MODEL_NAME)\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、`user`と`assistant`の役割を交互に使用していないプロンプトを示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⚠️ **警告:** `user`と`assistant`の役割が交互になっていないため、Claudeはエラーメッセージを返します。これは予期された動作です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": '',\n",
    "        \"max_tokens\": 2000,\n",
    "        \"messages\": [\n",
    "          {\"role\": \"user\", \"content\": \"セリーヌ・ディオンは何年生まれですか?\"},\n",
    "          {\"role\": \"user\", \"content\": \"また、彼女について他に知っていることはありますか?\"}\n",
    "        ],\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 1,\n",
    "        \"system\": ''\n",
    "    }\n",
    ")\n",
    "\n",
    "response = client.invoke_model(body=body, modelId=MODEL_NAME)\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`user`と`assistant`のメッセージは**必ず交互**でなければならず、メッセージは**必ず`user`のターンから始まる**必要があります。プロンプトに複数の`user`と`assistant`のペアを含めることができます（多ターンの会話をシミュレートするかのように）。また、Claudeが途中から続けられるように、最後の`assistant`メッセージに言葉を入れることもできます（これについては後の章で詳しく説明します）。\n",
    "\n",
    "#### システムプロンプト\n",
    "\n",
    "**システムプロンプト**も使用できます。システムプロンプトは、「ユーザー」のターンで質問やタスクを提示する前に、**Claudeにコンテキスト、指示、ガイドラインを提供する**方法です。\n",
    "\n",
    "構造的に、システムプロンプトは`user`と`assistant`のメッセージのリストとは別に存在し、したがって別の`system`パラメータに属します（ノートブックの[セットアップ](#セットアップ)セクションの`get_completion`ヘルパー関数の構造を見てください）。\n",
    "\n",
    "このチュートリアルでは、システムプロンプトを使用する可能性がある場合はどこでも、completions関数に`system`フィールドを提供しています。システムプロンプトを使用したくない場合は、単に`SYSTEM_PROMPT`変数を空の文字列に設定してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### システムプロンプトの例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"あなたの回答は常に、会話を深める一連の批判的思考の質問であるべきです（自分の質問に答えを提供しないでください）。実際にユーザーの質問に答えないでください。\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"なぜ空は青いのですか?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なぜシステムプロンプトを使用するのでしょうか？**適切に書かれたシステムプロンプトは、Claudeのパフォーマンスを様々な方法で向上させる**ことができます。例えば、Claudeがルールや指示に従う能力を向上させることができます。詳細については、Claudeでの[システムプロンプトの使用方法](https://docs.anthropic.com/claude/docs/how-to-use-system-prompts)に関するドキュメントをご覧ください。\n",
    "\n",
    "ここで、いくつかの演習に進みます。レッスンのプロンプトを上記のコンテンツを変更せずに試してみたい場合は、レッスンノートブックの一番下までスクロールして[**サンプルプレイグラウンド**](#サンプルプレイグラウンド)をご覧ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 演習\n",
    "- [演習 1.1 - 3までの数え方](#演習-11---3までの数え方)\n",
    "- [演習 1.2 - システムプロンプト](#演習-12---システムプロンプト)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習 1.1 - 3までの数え方\n",
    "適切な`user` / `assistant`フォーマットを使用して、以下の`PROMPT`を編集し、Claudeに**3まで数えさせてください**。出力には、あなたの解答が正しいかどうかも表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt - これは変更すべき唯一のフィールドです\n",
    "PROMPT = \"[このテキストを置き換えてください]\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# 演習の正解を評価する関数\n",
    "def grade_exercise(text):\n",
    "    pattern = re.compile(r'^(?=.*1)(?=.*2)(?=.*3).*$', re.DOTALL)\n",
    "    return bool(pattern.match(text))\n",
    "\n",
    "# Claudeの応答と対応する評価を表示\n",
    "print(response)\n",
    "print(\"\\n--------------------------- 評価 ---------------------------\")\n",
    "print(\"この演習は正しく解かれました：\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ ヒントが欲しい場合は、以下のセルを実行してください！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hints.exercise_1_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習 1.2 - システムプロンプト\n",
    "\n",
    "`SYSTEM_PROMPT`を修正して、Claudeが3歳の子供のように応答するようにしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# システムプロンプト - これは変更すべき唯一のフィールドです\n",
    "SYSTEM_PROMPT = \"[このテキストを置き換えてください]\"\n",
    "\n",
    "# プロンプト\n",
    "PROMPT = \"なぜ空は青いのですか?\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# 演習の正解を評価する関数\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(r\"わぁ\", text) or re.search(r\"だから\", text))\n",
    "\n",
    "# Claudeの応答と対応する評価を表示\n",
    "print(response)\n",
    "print(\"\\n--------------------------- 評価 ---------------------------\")\n",
    "print(\"この演習は正しく解かれました：\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ ヒントが欲しい場合は、以下のセルを実行してください！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hints.exercise_1_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### おめでとうございます！\n",
    "\n",
    "ここまですべての演習を解いたなら、次の章に進む準備ができています。プロンプトエンジニアリングを楽しんでください！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## サンプルプレイグラウンド\n",
    "\n",
    "ここは、このレッスンで示されたプロンプトの例を自由に試したり、プロンプトを微調整してClaudeの応答にどのような影響があるかを確認したりできる領域です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロンプト\n",
    "PROMPT = \"こんにちは、Claude。お元気ですか?\"\n",
    "\n",
    "# Claudeの応答を表示\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロンプト\n",
    "PROMPT = \"あなたは海の色をなんと呼んでいますか?\"\n",
    "\n",
    "# Claudeの応答を表示\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロンプト\n",
    "PROMPT = \"セリーヌ・ディオンは何年生まれですか?\"\n",
    "\n",
    "# Claudeの応答を表示\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": '',\n",
    "        \"max_tokens\": 2000,\n",
    "        \"messages\": [{\"こんにちは、Claude。お元気ですか?\"}],\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 1,\n",
    "        \"system\": ''\n",
    "    }\n",
    ")\n",
    "\n",
    "response = client.invoke_model(body=body, modelId=MODEL_NAME)\n",
    "\n",
    "# Claudeの応答を表示\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": '',\n",
    "        \"max_tokens\": 2000,\n",
    "        \"messages\": [\n",
    "          {\"role\": \"user\", \"content\": \"セリーヌ・ディオンは何年生まれですか?\"},\n",
    "          {\"role\": \"user\", \"content\": \"また、彼女について他に知っていることはありますか?\"}\n",
    "        ],\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 1,\n",
    "        \"system\": ''\n",
    "    }\n",
    ")\n",
    "\n",
    "response = client.invoke_model(body=body, modelId=MODEL_NAME)\n",
    "\n",
    "# Claudeの応答を表示\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# システムプロンプト\n",
    "SYSTEM_PROMPT = \"あなたの回答は常に、会話を深める一連の批判的思考の質問であるべきです（自分の質問に答えを提供しないでください）。実際にユーザーの質問に答えないでください。\"\n",
    "\n",
    "# プロンプト\n",
    "PROMPT = \"なぜ空は青いのですか?\"\n",
    "\n",
    "# Claudeの応答を表示\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
